{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "alike-morgan",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown, display, HTML\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from livelossplot import PlotLosses\n",
    "\n",
    "# Fix the dying kernel problem (only a problem in some installations - you can remove it, if it works without it)\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e40e9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                           Version\n",
      "--------------------------------- ---------------\n",
      "absl-py                           1.4.0\n",
      "aiofiles                          0.5.0\n",
      "alabaster                         0.7.12\n",
      "alembic                           1.7.7\n",
      "anaconda-client                   1.11.2\n",
      "anaconda-navigator                2.4.0\n",
      "anyio                             3.5.0\n",
      "appdirs                           1.4.4\n",
      "argon2-cffi                       21.3.0\n",
      "argon2-cffi-bindings              21.2.0\n",
      "arrow                             1.2.2\n",
      "asgi-lifespan                     2.1.0\n",
      "astroid                           2.6.6\n",
      "astropy                           5.1\n",
      "asttokens                         2.0.5\n",
      "astunparse                        1.6.3\n",
      "atomicwrites                      1.4.0\n",
      "attrs                             22.1.0\n",
      "Automat                           20.2.0\n",
      "autopep8                          1.6.0\n",
      "Babel                             2.11.0\n",
      "backcall                          0.2.0\n",
      "backports.functools-lru-cache     1.6.4\n",
      "backports.tempfile                1.0\n",
      "backports.weakref                 1.0.post1\n",
      "bcrypt                            3.2.0\n",
      "beanie                            1.18.0\n",
      "beautifulsoup4                    4.12.2\n",
      "binaryornot                       0.4.4\n",
      "black                             0.0\n",
      "bleach                            4.1.0\n",
      "bokeh                             2.4.3\n",
      "Bottleneck                        1.3.5\n",
      "brotlipy                          0.7.0\n",
      "certifi                           2022.12.7\n",
      "cffi                              1.15.1\n",
      "chardet                           4.0.0\n",
      "charset-normalizer                2.0.4\n",
      "click                             7.1.2\n",
      "cloudpickle                       2.0.0\n",
      "clyent                            1.2.2\n",
      "colorama                          0.4.6\n",
      "colorcet                          3.0.1\n",
      "comm                              0.1.2\n",
      "conda                             4.14.0\n",
      "conda-build                       3.24.0\n",
      "conda-content-trust               0.1.3\n",
      "conda-package-handling            2.0.2\n",
      "conda_package_streaming           0.7.0\n",
      "conda-repo-cli                    1.0.41\n",
      "conda-token                       0.4.0\n",
      "conda-verify                      3.4.2\n",
      "constantly                        15.1.0\n",
      "contourpy                         1.0.5\n",
      "cookiecutter                      1.7.3\n",
      "cryptography                      39.0.1\n",
      "cssselect                         1.1.0\n",
      "cycler                            0.11.0\n",
      "cytoolz                           0.12.0\n",
      "daal4py                           2023.0.2\n",
      "dask                              2023.3.2\n",
      "databricks-cli                    0.17.4\n",
      "datashader                        0.14.4\n",
      "datashape                         0.5.4\n",
      "debugpy                           1.5.1\n",
      "decorator                         5.1.1\n",
      "defusedxml                        0.7.1\n",
      "diff-match-patch                  20200713\n",
      "distributed                       2023.3.2\n",
      "dnspython                         2.3.0\n",
      "docker                            6.0.1\n",
      "docutils                          0.18.1\n",
      "ecdsa                             0.17.0\n",
      "entrypoints                       0.4\n",
      "et-xmlfile                        1.1.0\n",
      "exceptiongroup                    1.1.1\n",
      "executing                         0.8.3\n",
      "fastapi                           0.95.1\n",
      "fastjsonschema                    2.16.2\n",
      "filelock                          3.9.0\n",
      "flake8                            3.9.2\n",
      "Flask                             2.2.2\n",
      "flatbuffers                       23.3.3\n",
      "fonttools                         4.25.0\n",
      "fsspec                            2023.3.0\n",
      "future                            0.18.3\n",
      "gast                              0.4.0\n",
      "gensim                            4.3.0\n",
      "gitdb                             4.0.10\n",
      "GitPython                         3.1.31\n",
      "glob2                             0.7\n",
      "google-auth-oauthlib              0.4.6\n",
      "google-pasta                      0.2.0\n",
      "greenlet                          2.0.1\n",
      "h11                               0.13.0\n",
      "h5py                              3.7.0\n",
      "HeapDict                          1.0.1\n",
      "holoviews                         1.15.4\n",
      "httpcore                          0.17.0\n",
      "httptools                         0.5.0\n",
      "httpx                             0.24.0\n",
      "huggingface-hub                   0.10.1\n",
      "hvplot                            0.8.2\n",
      "hyperlink                         21.0.0\n",
      "hyperopt                          0.2.7\n",
      "idna                              3.4\n",
      "imagecodecs                       2021.8.26\n",
      "imageio                           2.26.0\n",
      "imagesize                         1.4.1\n",
      "imbalanced-learn                  0.10.1\n",
      "importlib-metadata                6.0.0\n",
      "importlib-resources               5.2.0\n",
      "incremental                       21.3.0\n",
      "inflection                        0.5.1\n",
      "iniconfig                         1.1.1\n",
      "intake                            0.6.8\n",
      "intervaltree                      3.1.0\n",
      "ipykernel                         6.19.2\n",
      "ipython                           8.12.0\n",
      "ipython-genutils                  0.2.0\n",
      "ipywidgets                        8.0.4\n",
      "isort                             5.9.3\n",
      "itemadapter                       0.3.0\n",
      "itemloaders                       1.0.4\n",
      "itsdangerous                      2.0.1\n",
      "jaraco.classes                    3.2.1\n",
      "jedi                              0.18.1\n",
      "Jinja2                            3.1.2\n",
      "jinja2-time                       0.2.0\n",
      "jmespath                          0.10.0\n",
      "joblib                            1.1.1\n",
      "json5                             0.9.6\n",
      "jsonschema                        4.17.3\n",
      "jupyter                           1.0.0\n",
      "jupyter_client                    7.4.9\n",
      "jupyter-console                   6.4.0\n",
      "jupyter-contrib-core              0.4.2\n",
      "jupyter-contrib-nbextensions      0.7.0\n",
      "jupyter_core                      5.3.0\n",
      "jupyter-events                    0.6.3\n",
      "jupyter-highlight-selected-word   0.2.0\n",
      "jupyter-latex-envs                1.4.6\n",
      "jupyter-nbextensions-configurator 0.6.1\n",
      "jupyter_server                    2.5.0\n",
      "jupyter_server_terminals          0.4.4\n",
      "jupyterlab                        3.5.3\n",
      "jupyterlab-pygments               0.1.2\n",
      "jupyterlab_server                 2.22.0\n",
      "jupyterlab-widgets                3.0.5\n",
      "keras                             2.11.0\n",
      "keyring                           23.13.1\n",
      "kiwisolver                        1.4.4\n",
      "lazy-model                        0.0.5\n",
      "lazy-object-proxy                 1.6.0\n",
      "libarchive-c                      2.9\n",
      "libclang                          15.0.6.1\n",
      "livelossplot                      0.5.5\n",
      "llvmlite                          0.39.1\n",
      "locket                            1.0.0\n",
      "lxml                              4.9.1\n",
      "lz4                               3.1.3\n",
      "Mako                              1.2.4\n",
      "Markdown                          3.4.1\n",
      "MarkupSafe                        2.1.1\n",
      "matplotlib                        3.7.1\n",
      "matplotlib-inline                 0.1.6\n",
      "mccabe                            0.6.1\n",
      "menuinst                          1.4.19\n",
      "mistune                           0.8.4\n",
      "mkl-fft                           1.3.1\n",
      "mkl-random                        1.2.2\n",
      "mkl-service                       2.4.0\n",
      "mlflow                            2.2.1\n",
      "mlops-ai                          1.1.0\n",
      "mock                              4.0.3\n",
      "more-itertools                    8.12.0\n",
      "motor                             3.1.2\n",
      "mpmath                            1.2.1\n",
      "msgpack                           1.0.3\n",
      "multipledispatch                  0.6.0\n",
      "munkres                           1.1.4\n",
      "mypy-extensions                   0.4.3\n",
      "navigator-updater                 0.3.0\n",
      "nbclassic                         0.5.5\n",
      "nbclient                          0.5.13\n",
      "nbconvert                         6.5.4\n",
      "nbformat                          5.7.0\n",
      "nest-asyncio                      1.5.6\n",
      "networkx                          2.8.4\n",
      "nltk                              3.7\n",
      "notebook                          6.5.4\n",
      "notebook_shim                     0.2.2\n",
      "numba                             0.56.4\n",
      "numexpr                           2.8.4\n",
      "numpy                             1.24.2\n",
      "numpydoc                          1.5.0\n",
      "oauthlib                          3.2.2\n",
      "openpyxl                          3.0.10\n",
      "opt-einsum                        3.3.0\n",
      "packaging                         23.0\n",
      "pandas                            1.5.3\n",
      "pandocfilters                     1.5.0\n",
      "panel                             0.14.3\n",
      "param                             1.12.3\n",
      "paramiko                          2.8.1\n",
      "parsel                            1.6.0\n",
      "parso                             0.8.3\n",
      "partd                             1.2.0\n",
      "passlib                           1.7.4\n",
      "pathlib                           1.0.1\n",
      "pathspec                          0.10.3\n",
      "patsy                             0.5.3\n",
      "pep8                              1.7.1\n",
      "pexpect                           4.8.0\n",
      "pickleshare                       0.7.5\n",
      "Pillow                            9.4.0\n",
      "pip                               23.0.1\n",
      "pkginfo                           1.9.6\n",
      "platformdirs                      3.1.0\n",
      "plotly                            5.9.0\n",
      "pluggy                            1.0.0\n",
      "pooch                             1.4.0\n",
      "poyo                              0.5.0\n",
      "prometheus-client                 0.14.1\n",
      "prompt-toolkit                    3.0.36\n",
      "Protego                           0.1.16\n",
      "psutil                            5.9.0\n",
      "psycopg2-binary                   2.9.3\n",
      "ptyprocess                        0.7.0\n",
      "pure-eval                         0.2.2\n",
      "py                                1.11.0\n",
      "py4j                              0.10.9.7\n",
      "pyarrow                           11.0.0\n",
      "pyasn1                            0.4.8\n",
      "pyasn1-modules                    0.2.8\n",
      "pycodestyle                       2.7.0\n",
      "pycosat                           0.6.4\n",
      "pycparser                         2.21\n",
      "pyct                              0.5.0\n",
      "pycurl                            7.45.2\n",
      "pydantic                          1.10.7\n",
      "PyDispatcher                      2.0.5\n",
      "pydocstyle                        6.3.0\n",
      "pyerfa                            2.0.0\n",
      "pyflakes                          2.3.1\n",
      "Pygments                          2.11.2\n",
      "PyHamcrest                        2.0.2\n",
      "PyJWT                             2.4.0\n",
      "pylint                            2.9.6\n",
      "pyls-spyder                       0.4.0\n",
      "pymongo                           4.3.3\n",
      "PyMySQL                           1.0.2\n",
      "PyNaCl                            1.4.0\n",
      "pyodbc                            4.0.34\n",
      "pyOpenSSL                         23.0.0\n",
      "pyparsing                         3.0.9\n",
      "PyQt5                             5.15.9\n",
      "PyQt5-Qt5                         5.15.2\n",
      "PyQt5-sip                         12.11.1\n",
      "pyrsistent                        0.18.0\n",
      "PySocks                           1.7.1\n",
      "pytest                            7.3.1\n",
      "pytest-asyncio                    0.21.0\n",
      "python-dateutil                   2.8.2\n",
      "python-decouple                   3.8\n",
      "python-dotenv                     1.0.0\n",
      "python-jose                       3.3.0\n",
      "python-json-logger                2.0.7\n",
      "python-lsp-black                  1.0.0\n",
      "python-lsp-jsonrpc                1.0.0\n",
      "python-lsp-server                 1.2.4\n",
      "python-multipart                  0.0.5\n",
      "python-slugify                    5.0.2\n",
      "python-snappy                     0.6.1\n",
      "pytoolconfig                      1.2.5\n",
      "pytz                              2022.7\n",
      "pyviz-comms                       2.0.2\n",
      "PyWavelets                        1.4.1\n",
      "pywin32                           305.1\n",
      "pywin32-ctypes                    0.2.0\n",
      "pywinpty                          2.0.10\n",
      "PyYAML                            6.0\n",
      "pyzmq                             25.0.2\n",
      "QDarkStyle                        3.0.2\n",
      "qstylizer                         0.2.2\n",
      "QtAwesome                         1.2.2\n",
      "qtconsole                         5.4.2\n",
      "QtPy                              2.2.0\n",
      "querystring-parser                1.2.4\n",
      "queuelib                          1.5.0\n",
      "regex                             2022.7.9\n",
      "requests                          2.28.1\n",
      "requests-file                     1.5.1\n",
      "requests-oauthlib                 1.3.1\n",
      "requests-toolbelt                 0.9.1\n",
      "rfc3339-validator                 0.1.4\n",
      "rfc3986-validator                 0.1.1\n",
      "rope                              1.7.0\n",
      "rsa                               4.8\n",
      "Rtree                             1.0.1\n",
      "ruamel.yaml                       0.17.21\n",
      "ruamel.yaml.clib                  0.2.7\n",
      "ruamel-yaml-conda                 0.15.100\n",
      "scikit-image                      0.19.3\n",
      "scikit-learn                      1.2.2\n",
      "scikit-learn-intelex              20230228.214139\n",
      "scipy                             1.10.1\n",
      "Scrapy                            2.8.0\n",
      "seaborn                           0.12.2\n",
      "Send2Trash                        1.8.0\n",
      "service-identity                  18.1.0\n",
      "setuptools                        66.0.0\n",
      "shap                              0.41.0\n",
      "sip                               4.19.13\n",
      "six                               1.16.0\n",
      "slicer                            0.0.7\n",
      "smart-open                        5.2.1\n",
      "smmap                             5.0.0\n",
      "sniffio                           1.2.0\n",
      "snowballstemmer                   2.2.0\n",
      "sortedcontainers                  2.4.0\n",
      "soupsieve                         2.4\n",
      "Sphinx                            5.0.2\n",
      "sphinxcontrib-applehelp           1.0.2\n",
      "sphinxcontrib-devhelp             1.0.2\n",
      "sphinxcontrib-htmlhelp            2.0.0\n",
      "sphinxcontrib-jsmath              1.0.1\n",
      "sphinxcontrib-qthelp              1.0.3\n",
      "sphinxcontrib-serializinghtml     1.1.5\n",
      "spyder                            5.1.5\n",
      "spyder-kernels                    2.1.3\n",
      "SQLAlchemy                        1.4.39\n",
      "sqlparse                          0.4.3\n",
      "stack-data                        0.2.0\n",
      "starlette                         0.26.1\n",
      "statsmodels                       0.13.5\n",
      "sympy                             1.11.1\n",
      "tables                            3.7.0\n",
      "tabulate                          0.8.10\n",
      "TBB                               0.2\n",
      "tblib                             1.7.0\n",
      "tenacity                          8.0.1\n",
      "tensorboard                       2.11.2\n",
      "tensorboard-data-server           0.6.1\n",
      "tensorboard-plugin-wit            1.8.1\n",
      "tensorflow                        2.11.0\n",
      "tensorflow-estimator              2.11.0\n",
      "tensorflow-intel                  2.11.0\n",
      "tensorflow-io-gcs-filesystem      0.31.0\n",
      "termcolor                         2.2.0\n",
      "terminado                         0.17.1\n",
      "text-unidecode                    1.3\n",
      "textdistance                      4.2.1\n",
      "threadpoolctl                     2.2.0\n",
      "three-merge                       0.1.1\n",
      "tifffile                          2021.7.2\n",
      "tinycss2                          1.2.1\n",
      "tldextract                        3.2.0\n",
      "tokenizers                        0.11.4\n",
      "toml                              0.10.2\n",
      "tomli                             2.0.1\n",
      "toolz                             0.12.0\n",
      "torch                             1.13.1\n",
      "tornado                           6.2\n",
      "tqdm                              4.65.0\n",
      "traitlets                         5.9.0\n",
      "transformers                      4.24.0\n",
      "Twisted                           22.2.0\n",
      "twisted-iocpsupport               1.0.2\n",
      "typing_extensions                 4.5.0\n",
      "ujson                             5.4.0\n",
      "Unidecode                         1.2.0\n",
      "urllib3                           1.26.15\n",
      "uvicorn                           0.21.1\n",
      "w3lib                             1.21.0\n",
      "waitress                          2.1.2\n",
      "watchdog                          2.1.6\n",
      "watchfiles                        0.19.0\n",
      "wcwidth                           0.2.5\n",
      "webencodings                      0.5.1\n",
      "websocket-client                  0.58.0\n",
      "websockets                        11.0.2\n",
      "Werkzeug                          2.2.3\n",
      "wheel                             0.38.4\n",
      "widgetsnbextension                4.0.5\n",
      "win-inet-pton                     1.1.0\n",
      "wrapt                             1.12.1\n",
      "xarray                            2022.11.0\n",
      "xgboost                           1.7.5\n",
      "xlwings                           0.29.1\n",
      "yapf                              0.31.0\n",
      "zict                              2.1.0\n",
      "zipp                              3.11.0\n",
      "zope.interface                    5.4.0\n",
      "zstandard                         0.19.0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "blessed-knitting",
   "metadata": {},
   "source": [
    "# Load the dataset for recommenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "victorian-bottom",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kacpe\\AppData\\Local\\Temp\\ipykernel_20248\\1822977472.py:16: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  interactions_df.loc[:, 'term'] = pd.Categorical(\n",
      "C:\\Users\\kacpe\\AppData\\Local\\Temp\\ipykernel_20248\\1822977472.py:18: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  interactions_df.loc[:, 'length_of_stay_bucket'] = pd.Categorical(\n",
      "C:\\Users\\kacpe\\AppData\\Local\\Temp\\ipykernel_20248\\1822977472.py:20: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  interactions_df.loc[:, 'rate_plan'] = pd.Categorical(\n",
      "C:\\Users\\kacpe\\AppData\\Local\\Temp\\ipykernel_20248\\1822977472.py:22: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  interactions_df.loc[:, 'room_segment'] = pd.Categorical(\n",
      "C:\\Users\\kacpe\\AppData\\Local\\Temp\\ipykernel_20248\\1822977472.py:24: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  interactions_df.loc[:, 'n_people_bucket'] = pd.Categorical(\n",
      "C:\\Users\\kacpe\\AppData\\Local\\Temp\\ipykernel_20248\\1822977472.py:27: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  interactions_df.loc[:, 'weekend_stay'] = pd.Categorical(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>term</th>\n",
       "      <th>length_of_stay_bucket</th>\n",
       "      <th>rate_plan</th>\n",
       "      <th>room_segment</th>\n",
       "      <th>n_people_bucket</th>\n",
       "      <th>weekend_stay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>Easter</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[1-1]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[1-1]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[1-1]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[1-1]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[8-inf]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>LowSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path = os.path.join(\"data\", \"hotel_data\")\n",
    "\n",
    "interactions_df = pd.read_csv(os.path.join(data_path, \"hotel_data_interactions_df.csv\"), index_col=0)\n",
    "\n",
    "base_item_features = ['term', 'length_of_stay_bucket', 'rate_plan', 'room_segment', 'n_people_bucket', 'weekend_stay']\n",
    "\n",
    "column_values_dict = {\n",
    "    'term': ['WinterVacation', 'Easter', 'OffSeason', 'HighSeason', 'LowSeason', 'MayLongWeekend', 'NewYear', 'Christmas'],\n",
    "    'length_of_stay_bucket': ['[0-1]', '[2-3]', '[4-7]', '[8-inf]'],\n",
    "    'rate_plan': ['Standard', 'Nonref'],\n",
    "    'room_segment': ['[0-160]', '[160-260]', '[260-360]', '[360-500]', '[500-900]'],\n",
    "    'n_people_bucket': ['[1-1]', '[2-2]', '[3-4]', '[5-inf]'],\n",
    "    'weekend_stay': ['True', 'False']\n",
    "}\n",
    "\n",
    "interactions_df.loc[:, 'term'] = pd.Categorical(\n",
    "    interactions_df['term'], categories=column_values_dict['term'])\n",
    "interactions_df.loc[:, 'length_of_stay_bucket'] = pd.Categorical(\n",
    "    interactions_df['length_of_stay_bucket'], categories=column_values_dict['length_of_stay_bucket'])\n",
    "interactions_df.loc[:, 'rate_plan'] = pd.Categorical(\n",
    "    interactions_df['rate_plan'], categories=column_values_dict['rate_plan'])\n",
    "interactions_df.loc[:, 'room_segment'] = pd.Categorical(\n",
    "    interactions_df['room_segment'], categories=column_values_dict['room_segment'])\n",
    "interactions_df.loc[:, 'n_people_bucket'] = pd.Categorical(\n",
    "    interactions_df['n_people_bucket'], categories=column_values_dict['n_people_bucket'])\n",
    "interactions_df.loc[:, 'weekend_stay'] = interactions_df['weekend_stay'].astype('str')\n",
    "interactions_df.loc[:, 'weekend_stay'] = pd.Categorical(\n",
    "    interactions_df['weekend_stay'], categories=column_values_dict['weekend_stay'])\n",
    "\n",
    "display(HTML(interactions_df.head(15).to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-third",
   "metadata": {},
   "source": [
    "# (Optional) Prepare numerical user features\n",
    "\n",
    "The method below is left here for convenience if you want to experiment with content-based user features as an input for your neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "variable-jaguar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user_length_of_stay_bucket_[0-1]', 'user_length_of_stay_bucket_[2-3]', 'user_length_of_stay_bucket_[4-7]', 'user_length_of_stay_bucket_[8-inf]', 'user_room_segment_[0-160]', 'user_room_segment_[160-260]', 'user_room_segment_[260-360]', 'user_room_segment_[360-500]', 'user_n_people_bucket_[1-1]', 'user_n_people_bucket_[2-2]', 'user_n_people_bucket_[3-4]', 'user_n_people_bucket_[5-inf]']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_length_of_stay_bucket_[0-1]</th>\n",
       "      <th>user_length_of_stay_bucket_[2-3]</th>\n",
       "      <th>user_length_of_stay_bucket_[4-7]</th>\n",
       "      <th>user_length_of_stay_bucket_[8-inf]</th>\n",
       "      <th>user_room_segment_[0-160]</th>\n",
       "      <th>user_room_segment_[160-260]</th>\n",
       "      <th>user_room_segment_[260-360]</th>\n",
       "      <th>user_room_segment_[360-500]</th>\n",
       "      <th>user_n_people_bucket_[1-1]</th>\n",
       "      <th>user_n_people_bucket_[2-2]</th>\n",
       "      <th>user_n_people_bucket_[3-4]</th>\n",
       "      <th>user_n_people_bucket_[5-inf]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>706</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>1736</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7301</th>\n",
       "      <td>7779</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def prepare_users_df(interactions_df):\n",
    "    users_df = interactions_df.copy()\n",
    "    base_features = ['length_of_stay_bucket', 'room_segment', 'n_people_bucket']\n",
    "    # Write your code here\n",
    "    users_df = interactions_df.groupby('user_id')[base_features].agg(lambda x: x.mode(dropna=False).iloc[0])\n",
    "    users_df = pd.get_dummies(users_df)\n",
    "    users_df = users_df.add_prefix('user_')\n",
    "    \n",
    "    user_features = users_df.columns.values.tolist()\n",
    "    users_df = users_df.reset_index()\n",
    "    \n",
    "    return users_df, user_features\n",
    "    \n",
    "\n",
    "users_df, user_features = prepare_users_df(interactions_df)\n",
    "\n",
    "print(user_features)\n",
    "\n",
    "display(HTML(users_df.loc[users_df['user_id'].isin([706, 1736, 7779, 96, 1, 50, 115])].head(15).to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-keyboard",
   "metadata": {},
   "source": [
    "# (Optional) Prepare numerical item features\n",
    "\n",
    "The method below is left here for convenience if you want to experiment with content-based item features as an input for your neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "formal-munich",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['term_WinterVacation', 'term_Easter', 'term_OffSeason', 'term_HighSeason', 'term_LowSeason', 'term_MayLongWeekend', 'term_NewYear', 'term_Christmas', 'length_of_stay_bucket_[0-1]', 'length_of_stay_bucket_[2-3]', 'length_of_stay_bucket_[4-7]', 'length_of_stay_bucket_[8-inf]', 'rate_plan_Standard', 'rate_plan_Nonref', 'room_segment_[0-160]', 'room_segment_[160-260]', 'room_segment_[260-360]', 'room_segment_[360-500]', 'room_segment_[500-900]', 'n_people_bucket_[1-1]', 'n_people_bucket_[2-2]', 'n_people_bucket_[3-4]', 'n_people_bucket_[5-inf]', 'weekend_stay_True', 'weekend_stay_False']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>term_WinterVacation</th>\n",
       "      <th>term_Easter</th>\n",
       "      <th>term_OffSeason</th>\n",
       "      <th>term_HighSeason</th>\n",
       "      <th>term_LowSeason</th>\n",
       "      <th>term_MayLongWeekend</th>\n",
       "      <th>term_NewYear</th>\n",
       "      <th>term_Christmas</th>\n",
       "      <th>length_of_stay_bucket_[0-1]</th>\n",
       "      <th>length_of_stay_bucket_[2-3]</th>\n",
       "      <th>length_of_stay_bucket_[4-7]</th>\n",
       "      <th>length_of_stay_bucket_[8-inf]</th>\n",
       "      <th>rate_plan_Standard</th>\n",
       "      <th>rate_plan_Nonref</th>\n",
       "      <th>room_segment_[0-160]</th>\n",
       "      <th>room_segment_[160-260]</th>\n",
       "      <th>room_segment_[260-360]</th>\n",
       "      <th>room_segment_[360-500]</th>\n",
       "      <th>room_segment_[500-900]</th>\n",
       "      <th>n_people_bucket_[1-1]</th>\n",
       "      <th>n_people_bucket_[2-2]</th>\n",
       "      <th>n_people_bucket_[3-4]</th>\n",
       "      <th>n_people_bucket_[5-inf]</th>\n",
       "      <th>weekend_stay_True</th>\n",
       "      <th>weekend_stay_False</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def prepare_items_df(interactions_df):\n",
    "    ########################\n",
    "    # Write your code here #\n",
    "    ########################\n",
    "    items_df = interactions_df.copy()\n",
    "    \n",
    "    items_df = pd.get_dummies(items_df[['item_id'] + base_item_features])\n",
    "    item_features = items_df.columns.tolist()\n",
    "    item_features.remove('item_id')\n",
    "    \n",
    "    items_df = items_df.drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    return items_df, item_features\n",
    "\n",
    "\n",
    "items_df, item_features = prepare_items_df(interactions_df)\n",
    "\n",
    "print(item_features)\n",
    "\n",
    "display(HTML(items_df.loc[items_df['item_id'].isin([0, 1, 2, 3, 4, 5, 6])].head(15).to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-imaging",
   "metadata": {},
   "source": [
    "# Neural network recommender\n",
    "\n",
    "<span style=\"color:red\"><font size=\"4\">**Task:**</font></span><br> \n",
    "Code a recommender based on a neural network model. You are free to choose any network architecture you find appropriate. The network can use the interaction vectors for users and items, embeddings of users and items, as well as user and item features (you can use the features you developed in the first project).\n",
    "\n",
    "Remember to keep control over randomness - in the init method add the seed as a parameter and initialize the random seed generator with that seed (both for numpy and pytorch):\n",
    "\n",
    "```python\n",
    "self.seed = seed\n",
    "self.rng = np.random.RandomState(seed=seed)\n",
    "```\n",
    "in the network model:\n",
    "```python\n",
    "self.seed = torch.manual_seed(seed)\n",
    "```\n",
    "\n",
    "You are encouraged to experiment with:\n",
    "  - the number of layers in the network, the number of neurons and different activation functions,\n",
    "  - different optimizers and their parameters,\n",
    "  - batch size and the number of epochs,\n",
    "  - embedding layers,\n",
    "  - content-based features of both users and items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-recipient",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.recommender import Recommender\n",
    "\n",
    "\n",
    "class NNRecommender(Recommender):\n",
    "    \"\"\"\n",
    "    Linear recommender class based on user and item features.\n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self, seed=6789, n_neg_per_pos=5, embedding_dim = 1000, n_epochs = 100, lr = 0.001, weight_decay = 0.0, hidden_1 = 5, hidden_2 = 2):\n",
    "        \"\"\"\n",
    "        Initialize recommender params and variables.\n",
    "        \"\"\"\n",
    "        self.model = None\n",
    "\n",
    "        self.device = RecommenderToolkit.get_device()\n",
    "        self.n_neg_per_pos = n_neg_per_pos\n",
    "        \n",
    "        self.recommender_df = pd.DataFrame(columns=['user_id', 'item_id', 'score'])\n",
    "        self.users_df = None\n",
    "        self.user_features = None\n",
    "        \n",
    "        self.seed = seed\n",
    "        self.rng = np.random.RandomState(seed=seed)\n",
    "\n",
    "        self.embedding_dim = emb_size\n",
    "        self.n_epochs = int(n_epochs)\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.hidden_1 = int(hidden_1)\n",
    "        self.hidden_2 = int(hidden_2)\n",
    "        self.criterion = nn.BCELoss()\n",
    "        \n",
    "        self.interactions_df = None\n",
    "        self.item_id_mapping = None\n",
    "        self.user_id_mapping = None\n",
    "        self.item_id_reverse_mapping = None\n",
    "        self.user_id_reverse_mapping = None\n",
    "    \n",
    "    def fit(self, interactions_df, users_df, items_df):\n",
    "        \"\"\"\n",
    "        Training of the recommender.\n",
    "        \n",
    "        :param pd.DataFrame interactions_df: DataFrame with recorded interactions between users and items \n",
    "            defined by user_id, item_id and features of the interaction.\n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features defined by user_id and the user feature columns.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features defined by item_id and the item feature columns.\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        unique_item_ids = interactions_df['item_id'].unique()\n",
    "        self.item_id_mapping = dict(zip(unique_item_ids, list(range(len(unique_item_ids)))))\n",
    "        self.item_id_reverse_mapping = dict(zip(list(range(len(unique_item_ids))), unique_item_ids))\n",
    "        \n",
    "        unique_user_ids = interactions_df['user_id'].unique()\n",
    "        self.user_id_mapping = dict(zip(unique_user_ids, list(range(len(unique_user_ids)))))\n",
    "        self.user_id_reverse_mapping = dict(zip(list(range(len(unique_user_ids))), unique_user_ids))\n",
    "        \n",
    "        interactions_df = interactions_df.copy()\n",
    "        interactions_df.replace({'item_id': self.item_id_mapping, 'user_id': self.user_id_mapping}, inplace=True)\n",
    "        \n",
    "        self.interactions_df = interactions_df.copy()\n",
    "        \n",
    "        # Prepare users_df and items_df \n",
    "        # (optional - use only if you want to train a hybrid model with content-based features)\n",
    "        \n",
    "        users_df, user_features = prepare_users_df(interactions_df)\n",
    "        \n",
    "        self.users_df = users_df\n",
    "        self.user_features = user_features\n",
    "        \n",
    "        items_df, item_features = prepare_items_df(interactions_df)\n",
    "        items_df = items_df.loc[:, ['item_id'] + item_features]\n",
    "        \n",
    "        # Generate negative interactions\n",
    "        \n",
    "        ########################\n",
    "        # Write your code here #\n",
    "        ########################\n",
    "        \n",
    "        interactions_df = interactions_df.loc[:, ['user_id', 'item_id']]\n",
    "        \n",
    "        interactions_df.loc[:, 'interacted'] = 1\n",
    "        \n",
    "        negative_interactions = []\n",
    "        \n",
    "        interacted_pairs = [(x, y) for x, y in zip(interactions_df[\"user_id\"], interactions_df[\"item_id\"])]\n",
    "        \n",
    "        user_ids = interactions_df['user_id'].unique()\n",
    "        item_ids = interactions_df['item_id'].unique()\n",
    "        \n",
    "        max_num_of_negative_interactions = self.n_neg_per_pos * len(interactions_df)\n",
    "        \n",
    "        while max_num_of_negative_interactions > len(negative_interactions):\n",
    "            user_id = np.random.choice(user_ids)\n",
    "            item_id = np.random.choice(item_ids)\n",
    "            \n",
    "            if (user_id, item_id) not in interacted_pairs:\n",
    "                negative_interactions.append((user_id, item_id, 0))\n",
    "        \n",
    "        interactions_df = pd.concat(\n",
    "            [interactions_df, pd.DataFrame(negative_interactions, columns=['user_id', 'item_id', 'interacted'])])\n",
    "        \n",
    "        # Merge user and item features\n",
    "        # (optional - use only if you want to train a hybrid model with content-based features)\n",
    "        \n",
    "        interactions_df = pd.merge(interactions_df, users_df, on=['user_id'])\n",
    "        interactions_df = pd.merge(interactions_df, items_df, on=['item_id'])\n",
    "\n",
    "        # Initialize the neural network model\n",
    "        \n",
    "        ########################\n",
    "        # Write your code here #\n",
    "        ########################\n",
    "        \n",
    "        # Train the model using an optimizer\n",
    "        \n",
    "        ########################\n",
    "        # Write your code here #\n",
    "        ########################\n",
    "    \n",
    "    def recommend(self, users_df, items_df, n_recommendations=1):\n",
    "        \"\"\"\n",
    "        Serving of recommendations. Scores items in items_df for each user in users_df and returns \n",
    "        top n_recommendations for each user.\n",
    "        \n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features for which recommendations should be generated.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features which should be scored.\n",
    "        :param int n_recommendations: Number of recommendations to be returned for each user.\n",
    "        :return: DataFrame with user_id, item_id and score as columns returning n_recommendations top recommendations \n",
    "            for each user.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "        \n",
    "        # Clean previous recommendations (iloc could be used alternatively)\n",
    "        self.recommender_df = self.recommender_df[:0]\n",
    "        \n",
    "        # Prepare users_df and items_df\n",
    "        # (optional - use only if you want to train a hybrid model with content-based features)\n",
    "        \n",
    "        users_df = users_df.loc[:, 'user_id']\n",
    "        users_df = pd.merge(users_df, self.users_df, on=['user_id'], how='left').fillna(0)\n",
    "        \n",
    "        items_df, item_features = prepare_items_df(items_df)\n",
    "        items_df = items_df.loc[:, ['item_id'] + item_features]\n",
    "        \n",
    "        # Score the items\n",
    "    \n",
    "        recommendations = pd.DataFrame(columns=['user_id', 'item_id', 'score'])\n",
    "        \n",
    "        for ix, user in users_df.iterrows():\n",
    "            \n",
    "            # Calculate the score for the user and every item in items_df\n",
    "            ########################\n",
    "            # Write your code here #\n",
    "            ########################\n",
    "            \n",
    "            scores = []\n",
    "\n",
    "            chosen_ids = np.argsort(-scores)[:n_recommendations]\n",
    "            \n",
    "            recommendations = []\n",
    "            for item_id in chosen_ids:\n",
    "                recommendations.append(\n",
    "                    {\n",
    "                        'user_id': user['user_id'],\n",
    "                        'item_id': item_id,\n",
    "                        'score': scores[item_id]\n",
    "                    }\n",
    "                )\n",
    "            \n",
    "            user_recommendations = pd.DataFrame(recommendations)\n",
    "\n",
    "            self.recommender_df = pd.concat([self.recommender_df, user_recommendations])\n",
    "\n",
    "        return self.recommender_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-relative",
   "metadata": {},
   "source": [
    "# Quick test of the recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greatest-canon",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df = interactions_df.loc[:, ['item_id'] + base_item_features].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit method\n",
    "nn_recommender = NNRecommender()\n",
    "nn_recommender.fit(interactions_df, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-consolidation",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Recommender method\n",
    "\n",
    "recommendations = nn_recommender.recommend(pd.DataFrame([[1], [2], [3], [4], [5]], columns=['user_id']), items_df, 10)\n",
    "\n",
    "recommendations = pd.merge(recommendations, items_df, on='item_id', how='left')\n",
    "display(HTML(recommendations.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-eleven",
   "metadata": {},
   "source": [
    "# Tuning method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-alaska",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_and_testing.testing import evaluate_train_test_split_implicit\n",
    "\n",
    "seed = 6789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-theta",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "import traceback\n",
    "\n",
    "def tune_recommender(recommender_class, interactions_df, items_df, \n",
    "                     param_space, max_evals=1, show_progressbar=True, seed=6789):\n",
    "    # Split into train_validation and test sets\n",
    "\n",
    "    shuffle = np.arange(len(interactions_df))\n",
    "    rng = np.random.RandomState(seed=seed)\n",
    "    rng.shuffle(shuffle)\n",
    "    shuffle = list(shuffle)\n",
    "\n",
    "    train_test_split = 0.8\n",
    "    split_index = int(len(interactions_df) * train_test_split)\n",
    "\n",
    "    train_validation = interactions_df.iloc[shuffle[:split_index]]\n",
    "    test = interactions_df.iloc[shuffle[split_index:]]\n",
    "\n",
    "    # Tune\n",
    "\n",
    "    def loss(tuned_params):\n",
    "        recommender = recommender_class(seed=seed, **tuned_params)\n",
    "        hr1, hr3, hr5, hr10, ndcg1, ndcg3, ndcg5, ndcg10 = evaluate_train_test_split_implicit(\n",
    "            recommender, train_validation, items_df, seed=seed)\n",
    "        return -hr10\n",
    "\n",
    "    n_tries = 1\n",
    "    succeded = False\n",
    "    try_id = 0\n",
    "    while not succeded and try_id < n_tries:\n",
    "        try:\n",
    "            trials = Trials()\n",
    "            best_param_set = fmin(loss, space=param_space, algo=tpe.suggest, \n",
    "                                  max_evals=max_evals, show_progressbar=show_progressbar, trials=trials, verbose=True)\n",
    "            succeded = True\n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "            try_id += 1\n",
    "            \n",
    "    if not succeded:\n",
    "        return None\n",
    "        \n",
    "    # Validate\n",
    "    \n",
    "    recommender = recommender_class(seed=seed, **best_param_set)\n",
    "\n",
    "    results = [[recommender_class.__name__] + list(evaluate_train_test_split_implicit(\n",
    "        recommender, {'train': train_validation, 'test': test}, items_df, seed=seed))]\n",
    "\n",
    "    results = pd.DataFrame(results, \n",
    "                           columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "    display(HTML(results.to_html()))\n",
    "    \n",
    "    return best_param_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reliable-switzerland",
   "metadata": {},
   "source": [
    "## Tuning of the recommender\n",
    "\n",
    "<span style=\"color:red\"><font size=\"4\">**Task:**</font></span><br> \n",
    "Tune your model using the code below. You only need to put the class name of your recommender and choose an appropriate parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-astrology",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = {\n",
    "    'n_neg_per_pos': hp.quniform('n_neg_per_pos', 1, 10, 1),\n",
    "    ########################\n",
    "    # Write your code here #\n",
    "    ########################\n",
    "}\n",
    "\n",
    "best_param_set = tune_recommender(NNRecommender, interactions_df, items_df,\n",
    "                                  param_space, max_evals=10, show_progressbar=True, seed=seed)\n",
    "\n",
    "print(\"Best parameters:\")\n",
    "print(best_param_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-strap",
   "metadata": {},
   "source": [
    "# Final evaluation\n",
    "\n",
    "<span style=\"color:red\"><font size=\"4\">**Task:**</font></span><br> \n",
    "Run the final evaluation of your recommender and present its results against the Amazon and Netflix recommenders' results. You just need to give the class name of your recommender and its tuned parameters below.\n",
    "\n",
    "It's optional, but for better effect you can include here the results from all recommenders created during in this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-homework",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_recommender = NNRecommender(n_neg_per_pos=1)  # Initialize your recommender here\n",
    "\n",
    "# Give the name of your recommender in the line below\n",
    "nn_tts_results = [['NNRecommender'] + list(evaluate_train_test_split_implicit(\n",
    "    nn_recommender, interactions_df, items_df))]\n",
    "\n",
    "nn_tts_results = pd.DataFrame(\n",
    "    nn_tts_results, columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(HTML(nn_tts_results.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-nomination",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.amazon_recommender import AmazonRecommender\n",
    "\n",
    "amazon_recommender = AmazonRecommender()\n",
    "\n",
    "amazon_tts_results = [['AmazonRecommender'] + list(evaluate_train_test_split_implicit(\n",
    "    amazon_recommender, interactions_df, items_df))]\n",
    "\n",
    "amazon_tts_results = pd.DataFrame(\n",
    "    amazon_tts_results, columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(HTML(amazon_tts_results.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-remedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.netflix_recommender import NetflixRecommender\n",
    "\n",
    "netflix_recommender = NetflixRecommender(embedding_dim=8, n_epochs=200, print_type='live')\n",
    "\n",
    "netflix_tts_results = [['NetflixRecommender'] + list(evaluate_train_test_split_implicit(\n",
    "    netflix_recommender, interactions_df, items_df))]\n",
    "\n",
    "netflix_tts_results = pd.DataFrame(\n",
    "    netflix_tts_results, columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(HTML(netflix_tts_results.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-printing",
   "metadata": {},
   "outputs": [],
   "source": [
    "tts_results = pd.concat([nn_tts_results, amazon_tts_results, netflix_tts_results]).reset_index(drop=True)\n",
    "display(HTML(tts_results.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-vegetable",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "<span style=\"color:red\"><font size=\"4\">**Task:**</font></span><br> \n",
    "Write a summary of your experiments. What worked well and what did not? What are your thoughts how could you possibly further improve the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-howard",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# Write your summary here #\n",
    "###########################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
